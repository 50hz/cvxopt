

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Support Vector Machines &mdash; CVXOPT</title>
    
    <link rel="stylesheet" href="../../_static/cvxopt.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '1.1.6',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  false
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="copyright" title="Copyright" href="../../copyright.html" />
    <link rel="top" title="CVXOPT" href="../../index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li><a href="../../index.html">CVXOPT</a> </li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="support-vector-machines">
<h1>Support Vector Machines<a class="headerlink" href="#support-vector-machines" title="Permalink to this headline">¶</a></h1>
<p>This software accompanies the paper <a class="reference external" href="http://www.ee.ucla.edu/~vandenbe/publications/svmcmpl.pdf">Support vector machine training
using matrix completion techniques</a> by
Martin Andersen and Lieven Vandenberghe. The code can be downloaded as
a <a class="reference download internal" href="../../_downloads/svmcmpl.zip"><tt class="xref download docutils literal"><span class="pre">zip</span> <span class="pre">file</span></tt></a> and
requires the Python extensions <a class="reference external" href="http://abel.ee.ucla.edu/cvxopt">CVXOPT</a> and <a class="reference external" href="http://abel.ee.ucla.edu/chompack">CHOMPACK</a>.</p>
<h4> Feedback and bug reports </h4><p>We welcome feedback, and bug reports are much appreciated. Please
email bug reports to <span class="raw-html"><kbd>msa@ee.ucla.edu</kbd></span>.</p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>This software provides two routines for soft-margin support vector
machine training. Both routines use the CVXOPT QP solver which
implements an interior-point method.</p>
<p>The routine <a class="reference internal" href="#softmargin" title="softmargin"><tt class="xref py py-func docutils literal"><span class="pre">softmargin()</span></tt></a> solves the standard SVM QP. It computes
and stores the entire kernel matrix, and hence it is only suited for
small problems.</p>
<p>The routine <a class="reference internal" href="#softmargin_appr" title="softmargin_appr"><tt class="xref py py-func docutils literal"><span class="pre">softmargin_appr()</span></tt></a> solves an <em>approximate problem</em> in
which the (generally dense) kernel matrix is replaced by a positive
definite approximation (the maximum determinant positive definite
completion of a partially specified kernel matrix) whose inverse is
sparse. This can be exploited in interior-point methods, and the
technique is implemented as a custom KKT solver for the CVXOPT QP
solver. As a consequence, <a class="reference internal" href="#softmargin_appr" title="softmargin_appr"><tt class="xref py py-func docutils literal"><span class="pre">softmargin_appr()</span></tt></a> can handle much
larger problems than <a class="reference internal" href="#softmargin" title="softmargin"><tt class="xref py py-func docutils literal"><span class="pre">softmargin()</span></tt></a>.</p>
</div>
<div class="section" id="documentation">
<h2>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="softmargin">
<tt class="descname">softmargin</tt><big>(</big><em>X</em>, <em>d</em>, <em>gamma</em>, <em>kernel = 'linear'</em>, <em>sigma = 1.0</em>, <em>degree = 1</em>, <em>theta = 1.0</em><big>)</big><a class="headerlink" href="#softmargin" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the &#8216;soft-margin&#8217; SVM problem</p>
<div class="math">
<p><img src="../../_images/math/53b1635c907783b3c1f4fd8c8808bab9a8d0bf48.png" alt="\begin{array}{ll}
\mbox{maximize}   &amp; -(1/2) z^T Q z + d^Tz \\
\mbox{subject to} &amp; 0 \preceq \mathrm{diag}(d) z \preceq \gamma \mathbf{1} \\
&amp; \mathbf{1}^T z =0
\end{array}"/></p>
</div><p>(with variables <img class="math" src="../../_images/math/b13f21416d84e13708696f34dea81026cda583c9.png" alt="z"/>), and its dual problem</p>
<div class="math">
<p><img src="../../_images/math/b7c1045941a2c4c5b4cbdfd0b9441d6dd9b49da1.png" alt="\begin{array}{ll}
\mbox{minimize}   &amp; (1/2) y^T Q^{-1} y + \gamma \mathbf{1}^Tv \\
\mbox{subject to} &amp;  \mathrm{diag}(d) (y + b \mathbf{1}) \succeq \mathbf{1} - v \\
&amp; v \succeq 0
\end{array}"/></p>
</div><p>(with variables <img class="math" src="../../_images/math/092e364e1d9d19ad5fffb0b46ef4cc7f2da02c1c.png" alt="y"/>, <img class="math" src="../../_images/math/a9f23bf124b6b2b2a993eb313c72e678664ac74a.png" alt="v"/>, <img class="math" src="../../_images/math/8136a7ef6a03334a7246df9097e5bcc31ba33fd2.png" alt="b"/>).</p>
<p>The <img class="math" src="../../_images/math/e75357f2d8c8407da3c37e1fa3524fbe8490e3f1.png" alt="m \times m"/> kernel matrix <img class="math" src="../../_images/math/9866e3a998d628ba0941eb4fea0666ac391d149a.png" alt="Q"/> is given by
<img class="math" src="../../_images/math/dd189f58da88b83eb11fe0d239bc6c9a890e88bc.png" alt="Q_{ij} = h(x_i, x_j)"/> where <img class="math" src="../../_images/math/8189a5b5a0917b8c93350827be4038af1839139d.png" alt="h"/> is a kernel function
and <img class="math" src="../../_images/math/8dc1ad02ea8728df79a2685e5f8ece035d555cb2.png" alt="x_i^T"/> is the i&#8217;th row of the <img class="math" src="../../_images/math/dc5c773a00becebf2fe78e775d5953e138efea9e.png" alt="m \times n"/> data
matrix <img class="math" src="../../_images/math/6a47ca0fe7cb276abc022af6ac88ddae1a9d6894.png" alt="X"/>, and <img class="math" src="../../_images/math/96ab646de7704969b91c76a214126b45f2b07b25.png" alt="d"/> is an <img class="math" src="../../_images/math/f5047d1e0cbb50ec208923a22cd517c55100fa7b.png" alt="m"/>-vector with labels
(<em>i.e.</em> <img class="math" src="../../_images/math/64ec7230e802f94c03fafa2ec6cf936f9f9c4b2e.png" alt="d_i \in \{ -1,1\}"/>).  If <img class="math" src="../../_images/math/9866e3a998d628ba0941eb4fea0666ac391d149a.png" alt="Q"/> is singular, we
replace <img class="math" src="../../_images/math/fa9fc986c845bdc80695fb750ad04c2fd299bd90.png" alt="Q^{-1}"/> in the dual with its pseudo-inverse and add
a constraint <img class="math" src="../../_images/math/fd09e3fee8b33de6917dc2a8f8a655e177877112.png" alt="y \in \mathrm{Range}(Q)"/>.</p>
<p>Valid kernel functions are:</p>
<dl class="docutils">
<dt><tt class="xref py py-const docutils literal"><span class="pre">'linear'</span></tt></dt>
<dd>the linear kernel: <img class="math" src="../../_images/math/236392056452ad28e3d88f670e8040a88448d647.png" alt="h(x_i,x_j) = x_i^Tx_j/\sigma"/></dd>
<dt><tt class="xref py py-const docutils literal"><span class="pre">'poly'</span></tt></dt>
<dd>the polynomial kernel: <img class="math" src="../../_images/math/cba09bc85d801e0fbc91c3f47800ce0041cea42a.png" alt="h(x_i,x_j) = (x_i^Tx_j/\sigma)^d"/></dd>
<dt><tt class="xref py py-const docutils literal"><span class="pre">'rbf'</span></tt></dt>
<dd>the radial basis function: <img class="math" src="../../_images/math/132b110917fc9a3e1501a276497017a0db394e4b.png" alt="h(x_i,x_j) = \exp\{ -\|x_i-x_j\|^2/(2\sigma)\}"/></dd>
<dt><tt class="xref py py-const docutils literal"><span class="pre">'tanh'</span></tt></dt>
<dd>the sigmoid kernel: <img class="math" src="../../_images/math/91efd18d75a3c8a2a1e475a6ced365942bc1aea0.png" alt="h(x_i,x_j) = \tanh(x_i^Tx_j/\sigma - \theta)"/></dd>
</dl>
<p>The kernel parameters <img class="math" src="../../_images/math/fa35d9fc104207e09a712110ac81612c5b279a6c.png" alt="\sigma"/>, <img class="math" src="../../_images/math/96ab646de7704969b91c76a214126b45f2b07b25.png" alt="d"/>, and <img class="math" src="../../_images/math/52e8ed7a3ba22130ad3984eb2cd413406475a689.png" alt="\theta"/>
are specified using the input arguments <cite>sigma</cite>, <cite>degree</cite>, and <cite>theta</cite>,
respectively.</p>
<p><a class="reference internal" href="#softmargin" title="softmargin"><tt class="xref py py-func docutils literal"><span class="pre">softmargin()</span></tt></a> returns a dictionary with the following keys:</p>
<dl class="docutils">
<dt><tt class="xref py py-const docutils literal"><span class="pre">'classifier'</span></tt></dt>
<dd>a Python function object that takes an
<img class="math" src="../../_images/math/e33e2ba3e206f98ba5aed5091b1f59b588115665.png" alt="M \times n"/> matrix with test vectors as rows and returns a vector with labels</dd>
<dt><tt class="xref py py-const docutils literal"><span class="pre">'z'</span></tt></dt>
<dd>a sparse <img class="math" src="../../_images/math/f5047d1e0cbb50ec208923a22cd517c55100fa7b.png" alt="m"/>-vector</dd>
<dt><tt class="xref py py-const docutils literal"><span class="pre">'cputime'</span></tt></dt>
<dd>a tuple (<img class="math" src="../../_images/math/294182e48abb2df54006ab495d26b45d0104a4c3.png" alt="T_{\rm tot}"/>, <img class="math" src="../../_images/math/ce14948d0925847886e886488ee7e9e0e20f9f0f.png" alt="T_{\rm qp}"/>,
<img class="math" src="../../_images/math/4041ff460b103d50ec1ae4956227053c90909fff.png" alt="T_{\rm ker}"/>) where <img class="math" src="../../_images/math/294182e48abb2df54006ab495d26b45d0104a4c3.png" alt="T_{\rm tot}"/> is the
total CPU time, <img class="math" src="../../_images/math/ce14948d0925847886e886488ee7e9e0e20f9f0f.png" alt="T_{\rm qp}"/> is the CPU time spent
solving the QP, and <img class="math" src="../../_images/math/4041ff460b103d50ec1ae4956227053c90909fff.png" alt="T_{\rm ker}"/> is the CPU time spent
computing the kernel matrix</dd>
<dt><tt class="xref py py-const docutils literal"><span class="pre">'iterations'</span></tt></dt>
<dd>the number of interior point iterations</dd>
<dt><tt class="xref py py-const docutils literal"><span class="pre">'misclassified'</span></tt></dt>
<dd>a tuple (<cite>L1</cite>, <cite>L2</cite>) where <cite>L1</cite> is a list
of indices of misclassified training vectors from class 1, and
<cite>L2</cite> is a list of indices of misclassified training vectors from
class 2</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="softmargin_appr">
<tt class="descname">softmargin_appr</tt><big>(</big><em>X</em>, <em>d</em>, <em>gamma</em>, <em>width</em>, <em>kernel = 'linear'</em>, <em>sigma = 1.0</em>, <em>degree = 1</em>, <em>theta = 1.0</em><big>)</big><a class="headerlink" href="#softmargin_appr" title="Permalink to this definition">¶</a></dt>
<dd><p>Solves the &#8216;soft-margin&#8217; SVM problem</p>
<div class="math">
<p><img src="../../_images/math/9d835a638b0396b4a0fc6e701dde1bab98153f27.png" alt="\begin{array}{ll}
\mbox{maximize}   &amp; -(1/2) z^T \tilde{Q} z + d^Tz \\
\mbox{subject to} &amp; 0 \preceq \mathrm{diag}(d) z \preceq \gamma \mathbf{1} \\
&amp; \mathbf{1}^T z =0
\end{array}"/></p>
</div><p>(with variables <img class="math" src="../../_images/math/b13f21416d84e13708696f34dea81026cda583c9.png" alt="z"/>), and its dual problem</p>
<div class="math">
<p><img src="../../_images/math/90f4c0343fe53d851b7ae25ad29b4511bf53fbdc.png" alt="\begin{array}{ll}
\mbox{minimize}   &amp; (1/2) y^T \tilde{Q}^{-1} y + \gamma \mathbf{1}^Tv \\
\mbox{subject to} &amp;  \mathrm{diag}(d) (y + b \mathbf{1}) \succeq \mathbf{1} - v \\
&amp; v \succeq 0
\end{array}"/></p>
</div><p>(with variables <img class="math" src="../../_images/math/092e364e1d9d19ad5fffb0b46ef4cc7f2da02c1c.png" alt="y"/>, <img class="math" src="../../_images/math/a9f23bf124b6b2b2a993eb313c72e678664ac74a.png" alt="v"/>, <img class="math" src="../../_images/math/8136a7ef6a03334a7246df9097e5bcc31ba33fd2.png" alt="b"/>).</p>
<p>The <img class="math" src="../../_images/math/e75357f2d8c8407da3c37e1fa3524fbe8490e3f1.png" alt="m \times m"/> kernel matrix <img class="math" src="../../_images/math/4df3d41f7ad18701c08febd524face293d826dc9.png" alt="\tilde{Q}"/> is the
maximum determinant completion of the projection of Q on a band
with bandwidth <img class="math" src="../../_images/math/5c32a6aa4ebe757e48c710bc37535999137258d4.png" alt="2w+1"/>. Here <img class="math" src="../../_images/math/dd189f58da88b83eb11fe0d239bc6c9a890e88bc.png" alt="Q_{ij} = h(x_i, x_j)"/> where
<img class="math" src="../../_images/math/8189a5b5a0917b8c93350827be4038af1839139d.png" alt="h"/> is one of the kernel functions defined under
<a class="reference internal" href="#softmargin" title="softmargin"><tt class="xref py py-func docutils literal"><span class="pre">softmargin()</span></tt></a> and <img class="math" src="../../_images/math/8dc1ad02ea8728df79a2685e5f8ece035d555cb2.png" alt="x_i^T"/> is the i&#8217;th row of the
<img class="math" src="../../_images/math/dc5c773a00becebf2fe78e775d5953e138efea9e.png" alt="m \times n"/> data matrix <img class="math" src="../../_images/math/6a47ca0fe7cb276abc022af6ac88ddae1a9d6894.png" alt="X"/>. The <img class="math" src="../../_images/math/f5047d1e0cbb50ec208923a22cd517c55100fa7b.png" alt="m"/>-vector
<img class="math" src="../../_images/math/96ab646de7704969b91c76a214126b45f2b07b25.png" alt="d"/> is a vector with labels (<em>i.e.</em> <img class="math" src="../../_images/math/284b511ee62758bd3b1f5bcf6b848a3ebd8b2bb2.png" alt="d_i \in \{
-1,1\}"/>).  The half-bandwidth parameter <img class="math" src="../../_images/math/9ee4b825a2e36ae093ed7be5e4851ef453b34914.png" alt="w"/> is set using the
input argument <cite>width</cite>.</p>
<p><tt class="xref py py-func docutils literal"><span class="pre">softmaring_appr()</span></tt> returns a dictionary that contains the same
keys as the dictionary returned by <a class="reference internal" href="#softmargin" title="softmargin"><tt class="xref py py-func docutils literal"><span class="pre">softmargin()</span></tt></a>. In
addition to these keys, the dictionary returned by
<a class="reference internal" href="#softmargin_appr" title="softmargin_appr"><tt class="xref py py-func docutils literal"><span class="pre">softmargin_appr()</span></tt></a> contains an second classifier:</p>
<dl class="docutils">
<dt><tt class="xref py py-const docutils literal"><span class="pre">'completion</span> <span class="pre">classifier'</span></tt></dt>
<dd>a Python function object that
takes an <img class="math" src="../../_images/math/e33e2ba3e206f98ba5aed5091b1f59b588115665.png" alt="M \times n"/> matrix with test vectors as rows
and returns a vector with labels</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="example-1">
<h2>Example 1<a class="headerlink" href="#example-1" title="Permalink to this headline">¶</a></h2>
<p>As a toy example, consider the following classification problem with
two (nonlinearly) separable classes.  We use as training set <img class="math" src="../../_images/math/f5047d1e0cbb50ec208923a22cd517c55100fa7b.png" alt="m"/>
points in <img class="math" src="../../_images/math/e89fe3f49396ca3fbf1f65bf8d276de262680fcc.png" alt="\mathbf{R}^2"/> generated according to a uniform
distribution over the box <img class="math" src="../../_images/math/f8d21ae40a4c7633ccd1eeeb710bed2cf071ea7a.png" alt="\mathcal{B} = \{ x\,|\,\|x\|_\infty
\leq 1 \}"/>. We assign labels using the function
<img class="math" src="../../_images/math/9f1aa249913115a0e7ed5f0924ceb17cf34ce49a.png" alt="\mathrm{sign}(f(x)) = \mathrm{sign}(x_1 x_2)"/>, <em>i.e.</em>, points
in the first and third quadrants belong to class 1 and points in the
second and fourth quadrants belong to class 2. We remark that in this
simple example, the degree 2 polynomial kernel can separate the two
classes.</p>
<p>The following Python code illustrates how to solve this classification
problem using each of the two routines provided in SVMCMPL.  In this
example we solve a problem instance with 2,000 training
points, and we use <img class="math" src="../../_images/math/8ab3d760ffa0294d7d4cd26e979767f51c676a24.png" alt="\gamma = 2.0"/> and the RBF kernel with
<img class="math" src="../../_images/math/1ce2a843a1917ff90480379a349baed419185551.png" alt="\sigma = 1.0"/>.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">cvxopt</span><span class="o">,</span> <span class="nn">svmcmpl</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">X</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">cvxopt</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">-</span><span class="mf">1.0</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">cvxopt</span><span class="o">.</span><span class="n">matrix</span><span class="p">([</span><span class="mi">2</span><span class="o">*</span><span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="o">&gt;=</span><span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">cvxopt</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])],(</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">;</span> <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#39;rbf&#39;</span><span class="p">;</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">sol1</span> <span class="o">=</span> <span class="n">svmcmpl</span><span class="o">.</span><span class="n">softmargin</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
<span class="n">sol2</span> <span class="o">=</span> <span class="n">svmcmpl</span><span class="o">.</span><span class="n">softmargin_appr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
</pre></div>
</div>
<p>Solving the standard (dense) SVM problem produced 445 support
vectors, marked with white dots in the plot below:</p>
<img alt="../../_images/xor_N2000_rbf.png" src="../../_images/xor_N2000_rbf.png" style="width: 450px;" />
<p>The solid curve marks the decision boundry whereas the dashed curves
are the -1 and +1 contours of <img class="math" src="../../_images/math/659a6a2610357101d77dbae8eb9bf0b3100c08fd.png" alt="g(x)"/> where
<img class="math" src="../../_images/math/0ca421acb2142f92b6b91084bfe7fb294b2343e8.png" alt="\mathrm{sign}(g(x))"/> is the decision function.</p>
<p>Solving the approximation problem with half-bandwidth <img class="math" src="../../_images/math/ed030775cf20cc4c52f0dcd9b4c6a5a074ce9025.png" alt="w = 10"/>
produced 1,054 support vectors.</p>
<img alt="../../_images/xor_N2000_rbf_skc_w10.png" src="../../_images/xor_N2000_rbf_skc_w10.png" style="width: 450px;" />
<img alt="../../_images/xor_N2000_rbf_ckc_w10.png" src="../../_images/xor_N2000_rbf_ckc_w10.png" style="width: 450px;" />
<p>In this example, the standard kernel classifier is clearly better than
the completion kernel classifier at this bandwidth. Increasing the
half-bandwidth to <img class="math" src="../../_images/math/908b2adac4b4dd629221cf1c3a3f7e73efa69912.png" alt="w = 20"/> produced 467 support vectors.</p>
<img alt="../../_images/xor_N2000_rbf_skc_w20.png" src="../../_images/xor_N2000_rbf_skc_w20.png" style="width: 450px;" />
<img alt="../../_images/xor_N2000_rbf_ckc_w20.png" src="../../_images/xor_N2000_rbf_ckc_w20.png" style="width: 450px;" />
<p>Notice that both the standard kernel and completion kernel classifiers
are now nearly identical to classifier obtained by solving the
standard SVM QP.</p>
<p>Solving the dense SVM QP required 7.0 seconds whereas the approximation
QPs required 0.3 seconds and 0.7 seconds for <img class="math" src="../../_images/math/ed030775cf20cc4c52f0dcd9b4c6a5a074ce9025.png" alt="w = 10"/> and <img class="math" src="../../_images/math/d080c79acd2d9d6776636261c17d304911243fa4.png" alt="w =
20"/>, respectively.</p>
</div>
<div class="section" id="example-2">
<h2>Example 2<a class="headerlink" href="#example-2" title="Permalink to this headline">¶</a></h2>
<p>The following example demonstrates the approximate SVM method on the
<a class="reference external" href="http://yann.lecun.com/exdb/mnist/">MNIST database</a> of handwritten
digits. In the example we use the Python module <a class="reference download internal" href="../../_downloads/mnist.py"><tt class="xref download docutils literal"><span class="pre">mnist.py</span></tt></a> to read the database files. The following code trains
a binary classifier using as training set 4,000 examples of the digit
&#8216;0&#8217; as class 1 and 4,000 examples of the digit &#8216;1&#8217; as class 2.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">mnist</span><span class="o">,</span> <span class="nn">svmcmpl</span><span class="o">,</span> <span class="nn">cvxopt</span><span class="o">,</span> <span class="nn">random</span>

<span class="n">digits1</span> <span class="o">=</span> <span class="p">[</span> <span class="mi">0</span> <span class="p">]</span>
<span class="n">digits2</span> <span class="o">=</span> <span class="p">[</span> <span class="mi">1</span> <span class="p">]</span>

<span class="n">m1</span> <span class="o">=</span> <span class="mi">4000</span><span class="p">;</span> <span class="n">m2</span> <span class="o">=</span> <span class="mi">4000</span>

<span class="c"># read training data</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">digits1</span> <span class="o">+</span> <span class="n">digits2</span><span class="p">,</span> <span class="n">dataset</span> <span class="o">=</span> <span class="s">&quot;training&quot;</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="s">&quot;data/mnist&quot;</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">images</span> <span class="o">/</span> <span class="mf">256.</span>

<span class="n">C1</span> <span class="o">=</span> <span class="p">[</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="k">if</span> <span class="n">labels</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="ow">in</span> <span class="n">digits1</span> <span class="p">]</span>
<span class="n">C2</span> <span class="o">=</span> <span class="p">[</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="k">if</span> <span class="n">labels</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="ow">in</span> <span class="n">digits2</span> <span class="p">]</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">()</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">C1</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">C2</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">C1</span><span class="p">[:</span><span class="n">m1</span><span class="p">]</span> <span class="o">+</span> <span class="n">C2</span><span class="p">[:</span><span class="n">m2</span><span class="p">]</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">train</span><span class="p">,:]</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">cvxopt</span><span class="o">.</span><span class="n">matrix</span><span class="p">([</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">k</span> <span class="ow">in</span> <span class="n">digits1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">[</span><span class="n">train</span><span class="p">]</span> <span class="p">])</span>

<span class="n">gamma</span> <span class="o">=</span> <span class="mf">4.0</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">svmcmpl</span><span class="o">.</span><span class="n">softmargin_appr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">kernel</span> <span class="o">=</span> <span class="s">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>In this example, both the standard kernel classifier and the completion kernel classifier misclassified 8 out of 2,115 test examples (digits &#8216;0&#8217; and &#8216;1&#8217; from the MNIST test set):</p>
<img alt="../../_images/mnist_miscls.png" src="../../_images/mnist_miscls.png" style="width: 450px;" />
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
    <h3>Contents</h3>
    <ul>
    <li><a href="../../index.html">Main</a></li>
    <li>
    <ul>
    <li><a href="../../copyright.html">Copyright and license</a></li>
    <li><a href="../../download/index.html">Download</a></li>
    <li><a href="../../install/index.html">Installation</a></li>
    <li><a href="../../documentation/index.html">Documentation</a></li>
    <li><a href="../../examples/index.html">Examples</a></li>
    <li><a href="../index.html">Applications</a></li>
    </ul>
    </li>
    </ul>
        <h3>This page</h3> <ul>
<li><a class="reference internal" href="#">Support Vector Machines</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#documentation">Documentation</a></li>
<li><a class="reference internal" href="#example-1">Example 1</a></li>
<li><a class="reference internal" href="#example-2">Example 2</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li><a href="../../index.html">CVXOPT</a> </li> 
      </ul>
    </div>
    <div class="footer">
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-2894407-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
  </body>
</html>